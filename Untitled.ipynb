{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d15e86e5-c5f8-4bfc-a0c0-8b2730c1e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "def stopping_criteria(alpha, iteration, epsilon=1e-5, max_steps=1e6):\n",
    "    # @alpha: alpha in this case can be the derivative/gradient or alpha itself\n",
    "    # @iteration: current iteration of the algorithm\n",
    "    # @epsilon: stopping value for alpha/graident. if alpha is smaller or equal\n",
    "    #           to epsilon the algorithm has to stop\n",
    "    # @max_steps: stopping value for iteration. if iteration is higher or equal\n",
    "    #             to max_steps the algorithm has to stop\n",
    "    # ToDo: Adjustments? Different Name for alpha? Should we parse more?\n",
    "    #       x_old/x_new, y_new/y_old?\n",
    "    return ((alpha <= epsilon) or (iteration >= max_steps))\n",
    "\n",
    "\n",
    "def wolfe(x0, p_k, fn, gradient_fn, rho, sigma, gama):\n",
    "    m = 0\n",
    "    mk = 0\n",
    "    gk = gradient_fn(x0)\n",
    "    while m < 20:\n",
    "        gk1 = gradient_fn(x0 + rho**m*p_k)\n",
    "        if fn(x0+rho**m*p_k) < fn(x0)+sigma*rho**m*np.dot(gk.T,p_k) and np.dot(gk1.T, p_k) >=  gama*np.dot(gk.T,p_k):\n",
    "            mk = m\n",
    "            break\n",
    "        m += 1\n",
    "    return rho**mk \n",
    "\n",
    "def cgm(xk, fn, gradient_fn, max_steps=1e2, epsilon=1e-5):\n",
    "    start_time = time.time()\n",
    "    grad_f_k = gradient_fn(xk)\n",
    "    p_k = - grad_f_k\n",
    "        \n",
    "    k=0\n",
    "    while np.any(grad_f_k):\n",
    "        # do line-search\n",
    "        alpha = wolfe(xk, p_k, fn, gradient_fn, 0.55, 0.55, 0.75)\n",
    "                \n",
    "        if stopping_criteria(alpha, k, epsilon, max_steps):\n",
    "          break\n",
    "        \n",
    "        xk = xk + alpha * p_k\n",
    "                \n",
    "        # fletcher-reeves\n",
    "        grad_f_k_next = gradient_fn(xk)\n",
    "        beta = (grad_f_k_next.T @ grad_f_k_next) / (grad_f_k.T @ grad_f_k)\n",
    "        # new search direction\n",
    "        p_k = (-grad_f_k_next) + beta * p_k\n",
    "        grad_f_k = grad_f_k_next\n",
    "        k+=1\n",
    "    \n",
    "    print(\"performed \" + str(k+1) + \" iterations.\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return xk\n",
    "\n",
    "\n",
    "def conjugate_gradient(start, fn, graident_fn, step_size=7 * (10 ** -6), epsilon=10 ** -6):\n",
    "    i = 0\n",
    "    x_values = [start]\n",
    "    p = []\n",
    "    norm_values = []\n",
    "    while True:\n",
    "        norm = np.linalg.norm(graident_fn(x_values[i]))\n",
    "        if norm < epsilon:\n",
    "            norm_values.append(norm)\n",
    "            break\n",
    "        else:\n",
    "            if i == 0:\n",
    "                p.append(- np.dot(step_size, graident_fn(x_values[i])))\n",
    "            else:\n",
    "                beta = np.dot(graident_fn(x_values[i]).T, graident_fn(x_values[i])) / \\\n",
    "                       np.dot(graident_fn(x_values[i - 1]).T, graident_fn(x_values[i - 1]))\n",
    "                p.append(-graident_fn(x_values[i]) + beta * p[i - 1])\n",
    "        x_values.append(x_values[i] + step_size * p[i])\n",
    "        norm_values.append(norm)\n",
    "        i += 1\n",
    "    return x_values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903d2b0b-ace1-4339-a1b7-7cb664c23af0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abc_6 = np.array([1, 20, 300])\n",
    "abc_7 = np.array([4, 50, 600])\n",
    "abc_8 = np.array([7, 80, 900])\n",
    "abc_9 = np.array([1, 100, 200])\n",
    "abc_10 = np.array([2, 120, 200])\n",
    "\n",
    "def get_global_minimizer(problem, stat_points):\n",
    "    y = []\n",
    "    for stat_point in np.array(stat_points).astype(float):\n",
    "        y.append([problem(stat_point), stat_point])\n",
    "    y = np.array(y)\n",
    "    return y[y[:,0].argsort()][0, 1]\n",
    "\n",
    "def problem_6(x):\n",
    "    return -(x*(3*x**3+(-4*abc_6[2]-4*abc_6[1]-4*abc_6[0])*x**2+((6*abc_6[1]+6*abc_6[0])*abc_6[2]+6*abc_6[0]*abc_6[1])*x-12*abc_6[0]*abc_6[1]*abc_6[2]))/12\n",
    "\n",
    "def derivative_problem_6(x):\n",
    "    return (abc_6[0]-x)*(abc_6[1]-x)*(abc_6[2]-x)\n",
    "\n",
    "def second_derivative_problem_6(x):\n",
    "    return -(abc_6[1]-x)*(abc_6[2]-x)-(abc_6[0]-x)*(abc_6[2]-x)-(abc_6[0]-x)*(abc_6[1]-x)\n",
    "\n",
    "def problem_7(x):\n",
    "    return -(x*(3*x**3+(-4*abc_7[2]-4*abc_7[1]-4*abc_7[0])*x**2+((6*abc_7[1]+6*abc_7[0])*abc_7[2]+6*abc_7[0]*abc_7[1])*x-12*abc_7[0]*abc_7[1]*abc_7[2]))/12\n",
    "\n",
    "def derivative_problem_7(x):\n",
    "    return (abc_7[0]-x)*(abc_7[1]-x)*(abc_7[2]-x)\n",
    "\n",
    "def second_derivative_problem_7(x):\n",
    "    return -(abc_7[1]-x)*(abc_7[2]-x)-(abc_7[0]-x)*(abc_7[2]-x)-(abc_7[0]-x)*(abc_7[1]-x)\n",
    "\n",
    "def problem_8(x):\n",
    "    return -(x*(3*x**3+(-4*abc_8[2]-4*abc_8[1]-4*abc_8[0])*x**2+((6*abc_8[1]+6*abc_8[0])*abc_8[2]+6*abc_8[0]*abc_8[1])*x-12*abc_8[0]*abc_8[1]*abc_8[2]))/12\n",
    "\n",
    "def derivative_problem_8(x):\n",
    "    return (abc_8[0]-x)*(abc_8[1]-x)*(abc_8[2]-x)\n",
    "\n",
    "def second_derivative_problem_8(x):\n",
    "    return -(abc_8[1]-x)*(abc_8[2]-x)-(abc_8[0]-x)*(abc_8[2]-x)-(abc_8[0]-x)*(abc_8[1]-x)\n",
    "\n",
    "def problem_9(x):\n",
    "    return -(x*(3*x**3+(-4*abc_9[2]-4*abc_9[1]-4*abc_9[0])*x**2+((6*abc_9[1]+6*abc_9[0])*abc_9[2]+6*abc_9[0]*abc_9[1])*x-12*abc_9[0]*abc_9[1]*abc_9[2]))/12\n",
    "\n",
    "def derivative_problem_9(x):\n",
    "    return (abc_9[0]-x)*(abc_9[1]-x)*(abc_9[2]-x)\n",
    "\n",
    "def second_derivative_problem_9(x):\n",
    "    return -(abc_9[1]-x)*(abc_9[2]-x)-(abc_9[0]-x)*(abc_9[2]-x)-(abc_9[0]-x)*(abc_9[1]-x)\n",
    "\n",
    "def problem_10(x):\n",
    "    return -(x*(3*x**3+(-4*abc_10[2]-4*abc_10[1]-4*abc_10[0])*x**2+((6*abc_10[1]+6*abc_10[0])*abc_10[2]+6*abc_10[0]*abc_10[1])*x-12*abc_10[0]*abc_10[1]*abc_10[2]))/12\n",
    "\n",
    "def derivative_problem_10(x):\n",
    "    return (abc_10[0]-x)*(abc_10[1]-x)*(abc_10[2]-x)\n",
    "\n",
    "def second_derivative_problem_10(x):\n",
    "    return -(abc_10[1]-x)*(abc_10[2]-x)-(abc_10[0]-x)*(abc_10[2]-x)-(abc_10[0]-x)*(abc_10[1]-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f4dbaf7-a78d-4476-b3f8-aa61dd516109",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated minimizer: 20.00000170632379\n",
      "real minimizers: [  1  20 300]\n",
      "estimated minimizer: 20.00000170632379\n",
      "real minimizers: [  1  20 300]\n",
      "estimated minimizer: 50.000000304170854\n",
      "real minimizers: [  4  50 600]\n",
      "estimated minimizer: 99.99999919649044\n",
      "real minimizers: [  1 100 200]\n"
     ]
    }
   ],
   "source": [
    "x_hat = conjugate_gradient(np.array([[100]], dtype=float), problem_6,  derivative_problem_6)\n",
    "print(\"estimated minimizer: \" + str(x_hat[0][-1][0][0]))\n",
    "print(\"real minimizers: \" + str(abc_6))\n",
    "\n",
    "x_hat = conjugate_gradient(np.array([[100]], dtype=float), problem_6,  derivative_problem_6)\n",
    "print(\"estimated minimizer: \" + str(x_hat[0][-1][0][0]))\n",
    "print(\"real minimizers: \" + str(abc_6))\n",
    "\n",
    "x_hat = conjugate_gradient(np.array([[100]], dtype=float), problem_7,  derivative_problem_7)\n",
    "print(\"estimated minimizer: \" + str(x_hat[0][-1][0][0]))\n",
    "print(\"real minimizers: \" + str(abc_7))\n",
    "\n",
    "x_hat = conjugate_gradient(np.array([[60]], dtype=float), problem_9,  derivative_problem_9)\n",
    "print(\"estimated minimizer: \" + str(x_hat[0][-1][0][0]))\n",
    "print(\"real minimizers: \" + str(abc_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da298ee2-0e95-49e7-b5eb-0bef771a3905",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_printout(x_0,x_optimal,x_appr,f,grad,args,tolerance):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    x_0: numpy 1D array, corresponds to initial point\n",
    "    x_optimal: numpy 1D array, corresponds to optimal point, which you know, or have solved analytically\n",
    "    x_appr: numpy 1D array, corresponds to approximated point, which your algorithm returned\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    f: function which takes 2 inputs: x (initial, optimal, or approximated)\n",
    "                                      **args\n",
    "       Function f returns a scalar output.\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    grad: function which takes 3 inputs: x (initial, optimal, or approximated), \n",
    "                                         function f,\n",
    "                                         args (which are submitted, because you might need\n",
    "                                              to call f(x,**args) inside your gradient function implementation). \n",
    "          Function grad approximates gradient at given point and returns a 1d np array.\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    args: dictionary, additional (except of x) arguments to function f\n",
    "    tolerance: float number, absolute tolerance, precision to which, you compare optimal and approximated solution.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Initial x is :\\t\\t{x_0}')\n",
    "    print(f'Optimal x is :\\t\\t{x_optimal}')\n",
    "    print(f'Approximated x is :\\t{x_appr}')\n",
    "    print(f'Is close verificaion: \\t{np.isclose(x_appr,x_optimal,atol=tolerance)}\\n')\n",
    "    f_opt = f(x_optimal)\n",
    "    f_appr = f(x_appr)\n",
    "    print(f'Function value in optimal point:\\t{f_opt}')\n",
    "    print(f'Function value in approximated point:   {f_appr}')\n",
    "    print(f'Is close verificaion:\\t{np.isclose(f_opt,f_appr,atol=tolerance)}\\n')\n",
    "    print(f'Gradient approximation in optimal point is:\\n{grad(x_optimal)}\\n')\n",
    "    grad_appr = grad(x_appr)\n",
    "    print(f'Gradient approximation in approximated point is:\\n{grad_appr}\\n')\n",
    "    print(f'Is close verificaion:\\n{np.isclose(grad_appr,np.zeros(grad_appr.shape),atol=tolerance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "612264e6-1841-4e1e-9850-17476e421e56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performed 16 iterations.\n",
      "--- 0.01251077651977539 seconds ---\n",
      "Initial x is :\t\t[[100.]]\n",
      "Optimal x is :\t\t20.0\n",
      "Approximated x is :\t[[20.00009022]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-328000.0\n",
      "Function value in approximated point:   [[-327999.99997835]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[0.47997628]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[False]]\n",
      "============================================================================\n",
      "performed 21 iterations.\n",
      "--- 0.018515825271606445 seconds ---\n",
      "Initial x is :\t\t[[100.]]\n",
      "Optimal x is :\t\t50.0\n",
      "Approximated x is :\t[[50.00000806]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-9062500.0\n",
      "Function value in approximated point:   [[-9062499.99999918]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[0.2040319]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[False]]\n",
      "============================================================================\n",
      "performed 11 iterations.\n",
      "--- 0.010009050369262695 seconds ---\n",
      "Initial x is :\t\t[[85.]]\n",
      "Optimal x is :\t\t80.0\n",
      "Approximated x is :\t[[79.96133298]]\n",
      "Is close verificaion: \t[[False]]\n",
      "\n",
      "Function value in optimal point:\t-53824000.0\n",
      "Function value in approximated point:   [[-53823955.26489358]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-2313.49112256]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[False]]\n",
      "============================================================================\n",
      "performed 21 iterations.\n",
      "--- 0.017014503479003906 seconds ---\n",
      "Initial x is :\t\t[[60.]]\n",
      "Optimal x is :\t\t100.0\n",
      "Approximated x is :\t[[100.03116022]]\n",
      "Is close verificaion: \t[[False]]\n",
      "\n",
      "Function value in optimal point:\t-24166666.666666668\n",
      "Function value in approximated point:   [[-24166661.86040923]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[308.48708666]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[False]]\n",
      "============================================================================\n",
      "performed 11 iterations.\n",
      "--- 0.009007930755615234 seconds ---\n",
      "Initial x is :\t\t[[100.]]\n",
      "Optimal x is :\t\t120.0\n",
      "Approximated x is :\t[[119.9999988]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-38016000.0\n",
      "Function value in approximated point:   [[-38015999.99999999]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-0.01135993]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "# #your code goes here\n",
    "x_start = np.array([[100]], dtype=float)\n",
    "x_hat = cgm(np.array([[100]], dtype=float), problem_6,  derivative_problem_6, epsilon=1e-7, max_steps=15)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_6, abc_6), x_appr=x_hat, f=problem_6, grad=derivative_problem_6, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=cgm(np.array([[100]], dtype=float), problem_7,  derivative_problem_7, epsilon=1e-7, max_steps=20)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_7, abc_7), x_appr=x_hat, f=problem_7, grad=derivative_problem_7, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start = np.array([[85]], dtype=float)\n",
    "x_hat=cgm(np.array([[85]], dtype=float), problem_8,  derivative_problem_8, epsilon=1e-7, max_steps=10)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_8, abc_8), x_appr=x_hat, f=problem_8, grad=derivative_problem_8, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start = np.array([[60]], dtype=float)\n",
    "x_hat=cgm(np.array([[60]], dtype=float), problem_9,  derivative_problem_9, epsilon=1e-7, max_steps=20)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_9, abc_9), x_appr=x_hat, f=problem_9, grad=derivative_problem_9, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start = np.array([[100]], dtype=float)\n",
    "x_hat=cgm(np.array([[100]], dtype=float), problem_10,  derivative_problem_10, epsilon=1e-5, max_steps=10)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_10, abc_10), x_appr=x_hat, f=problem_10, grad=derivative_problem_10, args={}, tolerance=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47628946-b4b3-4066-833f-ff7f2e3297db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "def get_random_A_b_minimizer(seed):\n",
    "    np.random.seed(seed)\n",
    "    A=np.random.randint(0, 2, (11, 11))\n",
    "    A=A@A.T\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    minimizer=np.random.randint(0, 10, (11, 1))\n",
    "\n",
    "    b=A@minimizer\n",
    "\n",
    "    return A, b, minimizer\n",
    "\n",
    "A_1, b_1, minimizer_1 = get_random_A_b_minimizer(0)\n",
    "A_2, b_2, minimizer_2 = get_random_A_b_minimizer(2)\n",
    "A_3, b_3, minimizer_3 = get_random_A_b_minimizer(3)\n",
    "A_4, b_4, minimizer_4 = get_random_A_b_minimizer(4)\n",
    "A_5, b_5, minimizer_5 = get_random_A_b_minimizer(6)\n",
    "A_6, b_6, minimizer_6 = get_random_A_b_minimizer(12)\n",
    "A_7, b_7, minimizer_7 = get_random_A_b_minimizer(15)\n",
    "\n",
    "def problem_1_q(x):\n",
    "    return (x.T@A_1@x)/2-b_1.T@x\n",
    "\n",
    "def grad_problem_1_q(x):\n",
    "    return np.dot(A_1,x)-b_1\n",
    "\n",
    "def hessian_problem_1_q(x):\n",
    "    return A_1\n",
    "\n",
    "def problem_2_q(x):\n",
    "    return (x.T@A_2@x)/2-b_2.T@x\n",
    "\n",
    "def grad_problem_2_q(x):\n",
    "    return A_2@x-b_2\n",
    "\n",
    "def hessian_problem_2_q(x):\n",
    "    return A_2\n",
    "\n",
    "def problem_3_q(x):\n",
    "    return (x.T@A_3@x)/2-b_3.T@x\n",
    "\n",
    "def grad_problem_3_q(x):\n",
    "    return A_3@x-b_3\n",
    "\n",
    "def hessian_problem_3_q(x):\n",
    "    return A_3\n",
    "\n",
    "def problem_4_q(x):\n",
    "    return (x.T@A_4@x)/2-b_4.T@x\n",
    "\n",
    "def grad_problem_4_q(x):\n",
    "    return A_4@x-b_4\n",
    "\n",
    "def hessian_problem_4_q(x):\n",
    "    return A_4\n",
    "\n",
    "def problem_5_q(x):\n",
    "    return (x.T@A_5@x)/2-b_5.T@x\n",
    "\n",
    "def grad_problem_5_q(x):\n",
    "    return A_5@x-b_5\n",
    "\n",
    "def hessian_problem_5_q(x):\n",
    "    return A_5\n",
    "\n",
    "def problem_6_q(x):\n",
    "    return (x.T@A_6@x)/2-b_6.T@x\n",
    "\n",
    "def grad_problem_6_q(x):\n",
    "    return A_6@x-b_6\n",
    "\n",
    "def hessian_problem_6_q(x):\n",
    "    return A_6\n",
    "\n",
    "def problem_7_q(x):\n",
    "    return (x.T@A_7@x)/2-b_7.T@x\n",
    "\n",
    "def grad_problem_7_q(x):\n",
    "    return A_7@x-b_7\n",
    "\n",
    "def hessian_problem_7_q(x):\n",
    "    return A_7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "576f7ac1-71b7-49b3-84e6-95e7448239f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[8]\n",
      " [8]\n",
      " [6]\n",
      " [2]\n",
      " [8]\n",
      " [7]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [4]\n",
      " [4]]\n",
      "Approximated x is :\t[[8.0000018 ]\n",
      " [7.99999714]\n",
      " [6.00000351]\n",
      " [2.00000472]\n",
      " [7.99999911]\n",
      " [6.99999544]\n",
      " [2.00000088]\n",
      " [0.99999679]\n",
      " [4.99999481]\n",
      " [4.0000001 ]\n",
      " [4.00000251]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4260.]]\n",
      "Function value in approximated point:   [[-4260.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 1.02042378e-07]\n",
      " [ 2.02076791e-07]\n",
      " [ 1.12779674e-07]\n",
      " [ 5.80856891e-07]\n",
      " [ 1.13066008e-07]\n",
      " [-4.86128897e-08]\n",
      " [ 4.40189865e-07]\n",
      " [ 9.21126571e-08]\n",
      " [-4.66384492e-07]\n",
      " [ 2.02124539e-07]\n",
      " [ 3.43481446e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[8]\n",
      " [9]\n",
      " [3]\n",
      " [8]\n",
      " [8]\n",
      " [0]\n",
      " [5]\n",
      " [3]\n",
      " [9]\n",
      " [9]\n",
      " [5]]\n",
      "Approximated x is :\t[[7.99999306e+00]\n",
      " [8.99998737e+00]\n",
      " [2.99999945e+00]\n",
      " [7.99999277e+00]\n",
      " [8.00000146e+00]\n",
      " [7.05162665e-06]\n",
      " [5.00000782e+00]\n",
      " [3.00000539e+00]\n",
      " [8.99999820e+00]\n",
      " [9.00000832e+00]\n",
      " [4.99998511e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-5551.5]]\n",
      "Function value in approximated point:   [[-5551.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-2.12264013e-07]\n",
      " [-6.43497259e-07]\n",
      " [ 2.57079677e-07]\n",
      " [-2.22747190e-07]\n",
      " [ 3.18898401e-07]\n",
      " [-1.91545240e-07]\n",
      " [ 7.74392674e-08]\n",
      " [ 1.99944566e-07]\n",
      " [-1.37480754e-07]\n",
      " [ 2.27881657e-07]\n",
      " [-4.08449299e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[7]\n",
      " [5]\n",
      " [1]\n",
      " [8]\n",
      " [7]\n",
      " [8]\n",
      " [2]\n",
      " [9]\n",
      " [7]\n",
      " [7]\n",
      " [7]]\n",
      "Approximated x is :\t[[7.00000655]\n",
      " [4.99999827]\n",
      " [1.00000099]\n",
      " [8.00000319]\n",
      " [6.99999369]\n",
      " [8.00000232]\n",
      " [2.0000037 ]\n",
      " [8.9999977 ]\n",
      " [6.99999468]\n",
      " [6.99999801]\n",
      " [7.00000419]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-6486.5]]\n",
      "Function value in approximated point:   [[-6486.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 1.25187569e-07]\n",
      " [-4.36316299e-07]\n",
      " [ 3.03612069e-08]\n",
      " [ 1.90713536e-07]\n",
      " [-1.59660431e-07]\n",
      " [ 8.42459826e-08]\n",
      " [ 6.72825422e-08]\n",
      " [-1.12605562e-07]\n",
      " [-6.55604083e-07]\n",
      " [-2.71126225e-07]\n",
      " [ 4.50958822e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[9]\n",
      " [3]\n",
      " [4]\n",
      " [0]\n",
      " [9]\n",
      " [1]\n",
      " [9]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [8]]\n",
      "Approximated x is :\t[[9.00009529e+00]\n",
      " [2.99990788e+00]\n",
      " [3.99987978e+00]\n",
      " [9.56948314e-05]\n",
      " [9.00007804e+00]\n",
      " [9.99918853e-01]\n",
      " [9.00002857e+00]\n",
      " [1.00005317e+00]\n",
      " [3.99991494e+00]\n",
      " [9.99979536e-01]\n",
      " [8.00005526e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4947.]]\n",
      "Function value in approximated point:   [[-4947.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 2.16070589e-07]\n",
      " [-3.02354692e-07]\n",
      " [-6.16196417e-07]\n",
      " [ 9.54258894e-08]\n",
      " [ 1.08877117e-07]\n",
      " [-1.90867240e-07]\n",
      " [-4.06348931e-07]\n",
      " [ 3.18298504e-07]\n",
      " [-1.50088795e-07]\n",
      " [-5.99833641e-08]\n",
      " [ 3.60402879e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [3]\n",
      " [0]\n",
      " [6]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [9]]\n",
      "Approximated x is :\t[[5.99998165e+00]\n",
      " [1.00005189e+00]\n",
      " [1.99999886e+00]\n",
      " [2.99997248e+00]\n",
      " [3.00002012e+00]\n",
      " [3.26832436e-05]\n",
      " [5.99998966e+00]\n",
      " [9.99966704e-01]\n",
      " [4.00001061e+00]\n",
      " [4.99994728e+00]\n",
      " [9.00004315e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-2939.5]]\n",
      "Function value in approximated point:   [[-2939.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-6.19234584e-08]\n",
      " [ 2.40211421e-07]\n",
      " [ 2.46568192e-07]\n",
      " [-7.16550403e-07]\n",
      " [ 6.76298555e-08]\n",
      " [-1.34886022e-08]\n",
      " [-9.18733178e-08]\n",
      " [ 1.88388896e-07]\n",
      " [ 1.90570574e-07]\n",
      " [-3.72286848e-07]\n",
      " [ 3.66828488e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[8]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [0]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [1]\n",
      " [7]\n",
      " [0]]\n",
      "Approximated x is :\t[[ 8.00000582e+00]\n",
      " [ 5.00000894e+00]\n",
      " [ 4.99999213e+00]\n",
      " [ 6.99999154e+00]\n",
      " [-8.64251154e-06]\n",
      " [ 7.00000983e+00]\n",
      " [ 5.00000039e+00]\n",
      " [ 5.99999416e+00]\n",
      " [ 1.00000270e+00]\n",
      " [ 6.99999006e+00]\n",
      " [ 5.02928596e-06]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4039.5]]\n",
      "Function value in approximated point:   [[-4039.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 3.66473898e-07]\n",
      " [ 2.34901194e-07]\n",
      " [-1.52380636e-07]\n",
      " [ 5.91731464e-09]\n",
      " [-6.36695887e-08]\n",
      " [ 6.53488485e-07]\n",
      " [ 1.38837521e-07]\n",
      " [-1.11157590e-08]\n",
      " [ 5.52073487e-07]\n",
      " [-1.68822098e-07]\n",
      " [ 3.66289328e-08]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "init=np.array([[6],[1],[2],[6],[7],[8],[1],[5],[1],[3],[6]])\n",
    "# x_hat=cgm(init, problem_1_q, grad_problem_1_q)\n",
    "# final_printout(init, minimizer_1, x_hat, problem_1_q, grad_problem_1_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=conjugate_gradient(init, problem_2_q, grad_problem_2_q)\n",
    "final_printout(init, minimizer_2, x_hat, problem_2_q, grad_problem_2_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=conjugate_gradient(init, problem_3_q, grad_problem_3_q)\n",
    "final_printout(init, minimizer_3, x_hat, problem_3_q, grad_problem_3_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=conjugate_gradient(init, problem_4_q, grad_problem_4_q)\n",
    "final_printout(init, minimizer_4, x_hat, problem_4_q, grad_problem_4_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=conjugate_gradient(init, problem_5_q, grad_problem_5_q)\n",
    "final_printout(init, minimizer_5, x_hat, problem_5_q, grad_problem_5_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=conjugate_gradient(init, problem_6_q, grad_problem_6_q)\n",
    "final_printout(init, minimizer_6, x_hat, problem_6_q, grad_problem_6_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=conjugate_gradient(init, problem_7_q, grad_problem_7_q)\n",
    "final_printout(init, minimizer_7, x_hat, problem_7_q, grad_problem_7_q, {}, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e05935-75e6-4e0c-8014-ab4188d29eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
