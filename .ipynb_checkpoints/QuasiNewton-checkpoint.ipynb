{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #D3D92B;\"><br>Numerical Optimisation. Project 1<br></h3><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #D3D92B;\"><br>Team Information<br></h3><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Group 7<br>\n",
    "Participants information in alphabetical order</i>\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th style = \"text-align: left\">#</th>\n",
    "    <th style = \"text-align: left\">Name</th>\n",
    "    <th style = \"text-align: left\">Lastname</th>\n",
    "    <th style = \"text-align: left\">Matr Number</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style = \"text-align: left\">1</td>\n",
    "    <td style = \"text-align: left\">Florian</td>\n",
    "    <td style = \"text-align: left\">Rothkegel</td>\n",
    "    <td style = \"text-align: left\">k11908775</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style = \"text-align: left\">2</td>\n",
    "    <td style = \"text-align: left\">Andreas</td>\n",
    "    <td style = \"text-align: left\">Oberdammer</td>\n",
    "    <td style = \"text-align: left\">k11908776</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style = \"text-align: left\">3</td>\n",
    "    <td style = \"text-align: left\">Martin</td>\n",
    "    <td style = \"text-align: left\">Zwiffl</td>\n",
    "    <td style = \"text-align: left\">k11910668</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style = \"text-align: left\">4</td>\n",
    "    <td style = \"text-align: left\">Martin</td>\n",
    "    <td style = \"text-align: left\">Stockinger</td>\n",
    "    <td style = \"text-align: left\">k01035089</td>\n",
    "    </tr>\n",
    "  <tr>\n",
    "    <td style = \"text-align: left\">5</td>\n",
    "    <td style = \"text-align: left\">Alexander</td>\n",
    "    <td style = \"text-align: left\">Mair</td>\n",
    "    <td style = \"text-align: left\">k11916624</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style = \"text-align: left\">6</td>\n",
    "    <td style = \"text-align: left\">Dominik</td>\n",
    "    <td style = \"text-align: left\">Zauner</td>\n",
    "    <td style = \"text-align: left\">k11717988</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #D3D92B;\"><br>Implementation<br></h3><br>\n",
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Imports<br></h4><br>\n",
    "<i>Describe how to install additional packages, if you have some, here</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Stopping criteria<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your function for stopping criterium\n",
    "def stopping_criteria(alpha, iteration, epsilon=1e-5, max_steps=1e6):\n",
    "    # @alpha: alpha in this case can be the derivative/gradient or alpha itself\n",
    "    # @iteration: current iteration of the algorithm\n",
    "    # @epsilon: stopping value for alpha/graident. if alpha is smaller or equal\n",
    "    #           to epsilon the algorithm has to stop\n",
    "    # @max_steps: stopping value for iteration. if iteration is higher or equal\n",
    "    #             to max_steps the algorithm has to stop\n",
    "    # ToDo: Adjustments? Different Name for alpha? Should we parse more?\n",
    "    #       x_old/x_new, y_new/y_old?\n",
    "    return ((alpha <= epsilon) or (iteration >= max_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Varibales scaling<br></h4><br>\n",
    "<i>Place your reasoning here, how your algorithm behave with respect to this problem. You can also try rescaling your problems\n",
    "This is additional task, which can earn you several points.<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Stabilising algorithm<br></h4><br>\n",
    "<i>Place your reasoning here, how your algorithm behave with respect to this problem. You can also try rescaling your problems\n",
    "This is additional task, which can earn you several points.<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your function for stabilising goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Fighting floating-point numbers and roundoff error<br></h4><br>\n",
    "<i>Place your reasoning, how your algorithm behave with respect to this problem. You can also try rescaling your problems\n",
    "This is additional task, which can earn you several points.<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Inverting matrices<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your function for invertion goes here\n",
    "def lu_deco_inverse(A):\n",
    "    n = A.shape[0]\n",
    "    a = np.copy(A.astype(float))\n",
    "    p = np.eye(n)\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        j = i + np.argmax(np.abs(a[i:, i]))     # maximum in column\n",
    "        if np.abs(a[i, j]) < 1e-8:\n",
    "            raise ValueError(\"Matrix is singular\")\n",
    "\n",
    "        if i != j:\n",
    "            a[[i, j]] = a[[j, i]]\n",
    "            p[[i, j]] = p[[j, i]]\n",
    "\n",
    "        for i_row in range(i + 1, n):\n",
    "            a[i_row, i] = a[i_row:, i] / a[i, i]\n",
    "        for i_row in range(i + 1, n):\n",
    "            for i_col in range(i + 1, n):\n",
    "                a[i_row, i_col] = a[i_row, i_col] - np.outer(a[i_row, i], a[i, i_col])\n",
    "\n",
    "    a_inv = np.copy(np.dot(p, np.eye(n)))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            a_inv[i] -= np.dot(a[i, j], a_inv[j])         # Forward substitution\n",
    "\n",
    "    for i in reversed(range(n)):\n",
    "        for j in range(i + 1, n):\n",
    "            a_inv[i] = (a_inv[i] - np.dot(a[i, j], a_inv[j])) / a[i, i]       # Backward substitution\n",
    "\n",
    "    return a_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Gradients calculation<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your function for gradient approximation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Additional objects you implemented<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Optimising algorithm itself<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "def wolfe(x0, p_k, fn, gradient_fn, rho, sigma, gama):\n",
    "    m = 0\n",
    "    mk = 0\n",
    "    gk = gradient_fn(x0)\n",
    "    while m < 20:\n",
    "        gk1 = gradient_fn(x0 + rho**m*p_k)\n",
    "        if fn(x0+rho**m*p_k) < fn(x0)+sigma*rho**m*np.dot(gk.T,p_k) and np.dot(gk1.T, p_k) >=  gama*np.dot(gk.T,p_k):\n",
    "            mk = m\n",
    "            break\n",
    "        m += 1\n",
    "    return rho**mk\n",
    "\n",
    "def bfgs(x0, fn, gradient_fn, epsilon=1e-5, max_steps=1e6,\n",
    "         activate_new_stop_crit=False,\n",
    "         activate_pre_scaling=False,\n",
    "         activate_alt_gradient=False,\n",
    "         activate_new_matrix_inversion=False):\n",
    "\n",
    "    k = 0\n",
    "    n = np.shape(x0)[0]\n",
    "    Bk = np.eye(n)\n",
    "\n",
    "    while True:\n",
    "        gk = gradient_fn(x0)\n",
    "        grad_norm = np.linalg.norm(gk)\n",
    "\n",
    "        if activate_new_stop_crit and stopping_criteria(grad_norm, k, epsilon, max_steps):\n",
    "            break\n",
    "\n",
    "        elif not activate_new_stop_crit and grad_norm <= epsilon:\n",
    "            break\n",
    "\n",
    "        p_k = -1.0*np.linalg.solve(Bk,gk)\n",
    "\n",
    "        alpha = wolfe(x0, p_k, fn, gradient_fn, 0.55, 0.4, 0.7)\n",
    "\n",
    "        x = x0 + alpha*p_k\n",
    "        sk = x - x0\n",
    "        yk = gradient_fn(x) - gk\n",
    "\n",
    "        if sk.T@yk > 0:\n",
    "            Bs = Bk@sk\n",
    "            ys = yk.T@sk\n",
    "            sBs = sk.T@Bk@sk\n",
    "            Bk = Bk-((Bs*sk.T@Bk)/sBs) + (yk*yk.T/ys)\n",
    "        k += 1\n",
    "        x0 = x\n",
    "    print(\"performed \" + str(k+1) + \" iterations.\")\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #D3D92B;\"><br>Testing on 5-10 variables, Quadratic objective<br></h3><br>\n",
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Implement functions to optimise over<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "def get_random_A_b_minimizer(seed):\n",
    "    np.random.seed(seed)\n",
    "    A=np.random.randint(0, 2, (11, 11))\n",
    "    A=A@A.T\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    minimizer=np.random.randint(0, 10, (11, 1))\n",
    "\n",
    "    b=A@minimizer\n",
    "\n",
    "    return A, b, minimizer\n",
    "\n",
    "A_1, b_1, minimizer_1 = get_random_A_b_minimizer(0)\n",
    "A_2, b_2, minimizer_2 = get_random_A_b_minimizer(2)\n",
    "A_3, b_3, minimizer_3 = get_random_A_b_minimizer(3)\n",
    "A_4, b_4, minimizer_4 = get_random_A_b_minimizer(4)\n",
    "A_5, b_5, minimizer_5 = get_random_A_b_minimizer(6)\n",
    "A_6, b_6, minimizer_6 = get_random_A_b_minimizer(12)\n",
    "A_7, b_7, minimizer_7 = get_random_A_b_minimizer(15)\n",
    "\n",
    "def problem_1_q(x):\n",
    "    return (x.T@A_1@x)/2-b_1.T@x\n",
    "\n",
    "def grad_problem_1_q(x):\n",
    "    return np.dot(A_1,x)-b_1\n",
    "\n",
    "def hessian_problem_1_q(x):\n",
    "    return A_1\n",
    "\n",
    "def problem_2_q(x):\n",
    "    return (x.T@A_2@x)/2-b_2.T@x\n",
    "\n",
    "def grad_problem_2_q(x):\n",
    "    return A_2@x-b_2\n",
    "\n",
    "def hessian_problem_2_q(x):\n",
    "    return A_2\n",
    "\n",
    "def problem_3_q(x):\n",
    "    return (x.T@A_3@x)/2-b_3.T@x\n",
    "\n",
    "def grad_problem_3_q(x):\n",
    "    return A_3@x-b_3\n",
    "\n",
    "def hessian_problem_3_q(x):\n",
    "    return A_3\n",
    "\n",
    "def problem_4_q(x):\n",
    "    return (x.T@A_4@x)/2-b_4.T@x\n",
    "\n",
    "def grad_problem_4_q(x):\n",
    "    return A_4@x-b_4\n",
    "\n",
    "def hessian_problem_4_q(x):\n",
    "    return A_4\n",
    "\n",
    "def problem_5_q(x):\n",
    "    return (x.T@A_5@x)/2-b_5.T@x\n",
    "\n",
    "def grad_problem_5_q(x):\n",
    "    return A_5@x-b_5\n",
    "\n",
    "def hessian_problem_5_q(x):\n",
    "    return A_5\n",
    "\n",
    "def problem_6_q(x):\n",
    "    return (x.T@A_6@x)/2-b_6.T@x\n",
    "\n",
    "def grad_problem_6_q(x):\n",
    "    return A_6@x-b_6\n",
    "\n",
    "def hessian_problem_6_q(x):\n",
    "    return A_6\n",
    "\n",
    "def problem_7_q(x):\n",
    "    return (x.T@A_7@x)/2-b_7.T@x\n",
    "\n",
    "def grad_problem_7_q(x):\n",
    "    return A_7@x-b_7\n",
    "\n",
    "def hessian_problem_7_q(x):\n",
    "    return A_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Run 5 tests<br></h4><br>\n",
    "<p><b>Note:</b> After every test print out the resulsts. \n",
    "<br>For your convinience we implemented a function which will do it for you. Function can be used in case after running optimisation you return $x_{optimal}$, and if you have implemented your gradient approximation. Feel free to bring your adjustments.\n",
    "<br> Additionaly print how many iterations your algotithm needed. You might also provide charts of your taste (if you want).\n",
    "<p><i>Place for your additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_printout(x_0,x_optimal,x_appr,f,grad,args,tolerance):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    x_0: numpy 1D array, corresponds to initial point\n",
    "    x_optimal: numpy 1D array, corresponds to optimal point, which you know, or have solved analytically\n",
    "    x_appr: numpy 1D array, corresponds to approximated point, which your algorithm returned\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    f: function which takes 2 inputs: x (initial, optimal, or approximated)\n",
    "                                      **args\n",
    "       Function f returns a scalar output.\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    grad: function which takes 3 inputs: x (initial, optimal, or approximated), \n",
    "                                         function f,\n",
    "                                         args (which are submitted, because you might need\n",
    "                                              to call f(x,**args) inside your gradient function implementation). \n",
    "          Function grad approximates gradient at given point and returns a 1d np array.\n",
    "    --------------------------------------------------------------------------------------------------------------\n",
    "    args: dictionary, additional (except of x) arguments to function f\n",
    "    tolerance: float number, absolute tolerance, precision to which, you compare optimal and approximated solution.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Initial x is :\\t\\t{x_0}')\n",
    "    print(f'Optimal x is :\\t\\t{x_optimal}')\n",
    "    print(f'Approximated x is :\\t{x_appr}')\n",
    "    print(f'Is close verificaion: \\t{np.isclose(x_appr,x_optimal,atol=tolerance)}\\n')\n",
    "    f_opt = f(x_optimal)\n",
    "    f_appr = f(x_appr)\n",
    "    print(f'Function value in optimal point:\\t{f_opt}')\n",
    "    print(f'Function value in approximated point:   {f_appr}')\n",
    "    print(f'Is close verificaion:\\t{np.isclose(f_opt,f_appr,atol=tolerance)}\\n')\n",
    "    print(f'Gradient approximation in optimal point is:\\n{grad(x_optimal)}\\n')\n",
    "    grad_appr = grad(x_appr)\n",
    "    print(f'Gradient approximation in approximated point is:\\n{grad_appr}\\n')\n",
    "    print(f'Is close verificaion:\\n{np.isclose(grad_appr,np.zeros(grad_appr.shape),atol=tolerance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performed 22 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[5]\n",
      " [0]\n",
      " [3]\n",
      " [3]\n",
      " [7]\n",
      " [9]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [7]]\n",
      "Approximated x is :\t[[ 5.00000540e+00]\n",
      " [-9.47437372e-06]\n",
      " [ 2.99999829e+00]\n",
      " [ 3.00000144e+00]\n",
      " [ 7.00000419e+00]\n",
      " [ 8.99998843e+00]\n",
      " [ 3.00000317e+00]\n",
      " [ 5.00000076e+00]\n",
      " [ 1.99999769e+00]\n",
      " [ 4.00000085e+00]\n",
      " [ 6.99999875e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4286.5]]\n",
      "Function value in approximated point:   [[-4286.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 2.26657107e-07]\n",
      " [-3.14650137e-07]\n",
      " [-2.84680482e-07]\n",
      " [ 4.84302518e-08]\n",
      " [ 8.34548928e-08]\n",
      " [-3.51915247e-07]\n",
      " [ 1.01022692e-08]\n",
      " [ 3.76091407e-08]\n",
      " [-3.26768088e-08]\n",
      " [ 1.30162846e-07]\n",
      " [ 2.50531471e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "performed 22 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[8]\n",
      " [8]\n",
      " [6]\n",
      " [2]\n",
      " [8]\n",
      " [7]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [4]\n",
      " [4]]\n",
      "Approximated x is :\t[[8.00000715]\n",
      " [7.99998787]\n",
      " [6.00001746]\n",
      " [2.00002663]\n",
      " [8.00000409]\n",
      " [6.99998045]\n",
      " [2.00000045]\n",
      " [0.99998067]\n",
      " [4.99999119]\n",
      " [4.00000125]\n",
      " [4.00000154]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4260.]]\n",
      "Function value in approximated point:   [[-4260.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 2.00218267e-06]\n",
      " [-7.19127911e-07]\n",
      " [ 9.72223916e-07]\n",
      " [ 2.64710469e-06]\n",
      " [-1.98189588e-06]\n",
      " [-2.47389389e-06]\n",
      " [-7.17615592e-07]\n",
      " [ 7.62887026e-07]\n",
      " [-4.12861809e-07]\n",
      " [ 4.58413867e-06]\n",
      " [-5.44464604e-06]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "performed 23 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[8]\n",
      " [9]\n",
      " [3]\n",
      " [8]\n",
      " [8]\n",
      " [0]\n",
      " [5]\n",
      " [3]\n",
      " [9]\n",
      " [9]\n",
      " [5]]\n",
      "Approximated x is :\t[[7.99999870e+00]\n",
      " [8.99999715e+00]\n",
      " [2.99999777e+00]\n",
      " [7.99999846e+00]\n",
      " [8.00000010e+00]\n",
      " [3.79000235e-07]\n",
      " [5.00000104e+00]\n",
      " [3.00000311e+00]\n",
      " [8.99999952e+00]\n",
      " [9.00000243e+00]\n",
      " [4.99999612e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-5551.5]]\n",
      "Function value in approximated point:   [[-5551.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 8.97168803e-07]\n",
      " [ 7.28881645e-07]\n",
      " [-5.46363154e-07]\n",
      " [ 8.61808161e-07]\n",
      " [ 1.35998670e-06]\n",
      " [-3.09236185e-07]\n",
      " [ 1.68893223e-07]\n",
      " [ 1.25388075e-06]\n",
      " [ 3.08875599e-07]\n",
      " [ 8.33007221e-07]\n",
      " [-7.95822285e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "performed 19 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[7]\n",
      " [5]\n",
      " [1]\n",
      " [8]\n",
      " [7]\n",
      " [8]\n",
      " [2]\n",
      " [9]\n",
      " [7]\n",
      " [7]\n",
      " [7]]\n",
      "Approximated x is :\t[[6.99999158]\n",
      " [5.00000058]\n",
      " [0.99999859]\n",
      " [7.99999126]\n",
      " [6.99999307]\n",
      " [8.00001333]\n",
      " [1.99999424]\n",
      " [8.99999294]\n",
      " [7.00001093]\n",
      " [6.99999907]\n",
      " [7.00000175]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-6486.5]]\n",
      "Function value in approximated point:   [[-6486.5]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-2.57420214e-06]\n",
      " [-1.34407102e-06]\n",
      " [-1.91961379e-06]\n",
      " [-1.82517755e-06]\n",
      " [-3.26541812e-06]\n",
      " [ 3.31988554e-06]\n",
      " [-1.55408620e-06]\n",
      " [-2.00595036e-06]\n",
      " [ 7.65379269e-07]\n",
      " [-4.44552228e-07]\n",
      " [-1.96652732e-06]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "performed 26 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[9]\n",
      " [3]\n",
      " [4]\n",
      " [0]\n",
      " [9]\n",
      " [1]\n",
      " [9]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [8]]\n",
      "Approximated x is :\t[[ 8.99998952e+00]\n",
      " [ 3.00001037e+00]\n",
      " [ 4.00001495e+00]\n",
      " [-1.20322500e-05]\n",
      " [ 8.99998986e+00]\n",
      " [ 1.00001067e+00]\n",
      " [ 8.99999554e+00]\n",
      " [ 9.99994148e-01]\n",
      " [ 4.00001163e+00]\n",
      " [ 1.00000141e+00]\n",
      " [ 7.99999390e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4947.]]\n",
      "Function value in approximated point:   [[-4947.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 3.64692369e-07]\n",
      " [-6.45692353e-08]\n",
      " [-4.55269969e-07]\n",
      " [ 6.35021138e-08]\n",
      " [-3.18123199e-07]\n",
      " [ 1.71264927e-06]\n",
      " [ 5.14106546e-07]\n",
      " [ 1.26861821e-06]\n",
      " [ 1.17256928e-06]\n",
      " [-1.18376488e-06]\n",
      " [ 5.91593420e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "performed 26 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[9]\n",
      " [3]\n",
      " [4]\n",
      " [0]\n",
      " [9]\n",
      " [1]\n",
      " [9]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [8]]\n",
      "Approximated x is :\t[[ 8.99998952e+00]\n",
      " [ 3.00001037e+00]\n",
      " [ 4.00001495e+00]\n",
      " [-1.20322500e-05]\n",
      " [ 8.99998986e+00]\n",
      " [ 1.00001067e+00]\n",
      " [ 8.99999554e+00]\n",
      " [ 9.99994148e-01]\n",
      " [ 4.00001163e+00]\n",
      " [ 1.00000141e+00]\n",
      " [ 7.99999390e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4947.]]\n",
      "Function value in approximated point:   [[-4947.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 3.64692369e-07]\n",
      " [-6.45692353e-08]\n",
      " [-4.55269969e-07]\n",
      " [ 6.35021138e-08]\n",
      " [-3.18123199e-07]\n",
      " [ 1.71264927e-06]\n",
      " [ 5.14106546e-07]\n",
      " [ 1.26861821e-06]\n",
      " [ 1.17256928e-06]\n",
      " [-1.18376488e-06]\n",
      " [ 5.91593420e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "============================================================================\n",
      "performed 26 iterations.\n",
      "Initial x is :\t\t[[6]\n",
      " [1]\n",
      " [2]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [6]]\n",
      "Optimal x is :\t\t[[9]\n",
      " [3]\n",
      " [4]\n",
      " [0]\n",
      " [9]\n",
      " [1]\n",
      " [9]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [8]]\n",
      "Approximated x is :\t[[ 8.99998952e+00]\n",
      " [ 3.00001037e+00]\n",
      " [ 4.00001495e+00]\n",
      " [-1.20322500e-05]\n",
      " [ 8.99998986e+00]\n",
      " [ 1.00001067e+00]\n",
      " [ 8.99999554e+00]\n",
      " [ 9.99994148e-01]\n",
      " [ 4.00001163e+00]\n",
      " [ 1.00000141e+00]\n",
      " [ 7.99999390e+00]]\n",
      "Is close verificaion: \t[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "Function value in optimal point:\t[[-4947.]]\n",
      "Function value in approximated point:   [[-4947.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[ 3.64692369e-07]\n",
      " [-6.45692353e-08]\n",
      " [-4.55269969e-07]\n",
      " [ 6.35021138e-08]\n",
      " [-3.18123199e-07]\n",
      " [ 1.71264927e-06]\n",
      " [ 5.14106546e-07]\n",
      " [ 1.26861821e-06]\n",
      " [ 1.17256928e-06]\n",
      " [-1.18376488e-06]\n",
      " [ 5.91593420e-07]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "init=np.array([[6],[1],[2],[6],[7],[8],[1],[5],[1],[3],[6]])\n",
    "x_hat=bfgs(init, problem_1_q, grad_problem_1_q)\n",
    "final_printout(init, minimizer_1, x_hat, problem_1_q, grad_problem_1_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=bfgs(init, problem_2_q, grad_problem_2_q)\n",
    "final_printout(init, minimizer_2, x_hat, problem_2_q, grad_problem_2_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=bfgs(init, problem_3_q, grad_problem_3_q)\n",
    "final_printout(init, minimizer_3, x_hat, problem_3_q, grad_problem_3_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=bfgs(init, problem_4_q, grad_problem_4_q)\n",
    "final_printout(init, minimizer_4, x_hat, problem_4_q, grad_problem_4_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=bfgs(init, problem_5_q, grad_problem_5_q)\n",
    "final_printout(init, minimizer_5, x_hat, problem_5_q, grad_problem_5_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=bfgs(init, problem_6_q, grad_problem_6_q)\n",
    "final_printout(init, minimizer_6, x_hat, problem_6_q, grad_problem_6_q, {}, 1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_hat=bfgs(init, problem_7_q, grad_problem_7_q)\n",
    "final_printout(init, minimizer_7, x_hat, problem_7_q, grad_problem_7_q, {}, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Here is some place for your analysis. How the behavour of algorithm changed after adjustments? What are specific details, differences you noticed with respect to other algorithms behaviour.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #D3D92B;\"><br>Testing on functions of 1-2 variables, Non-quadratic objective<br></h3><br>\n",
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Implement functions to optimise over<br></h4><br>\n",
    "<i>Place for additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "abc_6 = np.array([1, 20, 300])\n",
    "abc_7 = np.array([4, 50, 600])\n",
    "abc_8 = np.array([7, 80, 900])\n",
    "abc_9 = np.array([1, 100, 200])\n",
    "abc_10 = np.array([2, 120, 200])\n",
    "\n",
    "def get_global_minimizer(problem, stat_points):\n",
    "    y = []\n",
    "    for stat_point in np.array(stat_points).astype(float):\n",
    "        y.append([problem(stat_point), stat_point])\n",
    "    y = np.array(y)\n",
    "    return y[y[:,0].argsort()][0, 1]\n",
    "\n",
    "def problem_6(x):\n",
    "    return -(x*(3*x**3+(-4*abc_6[2]-4*abc_6[1]-4*abc_6[0])*x**2+((6*abc_6[1]+6*abc_6[0])*abc_6[2]+6*abc_6[0]*abc_6[1])*x-12*abc_6[0]*abc_6[1]*abc_6[2]))/12\n",
    "\n",
    "def derivative_problem_6(x):\n",
    "    return (abc_6[0]-x)*(abc_6[1]-x)*(abc_6[2]-x)\n",
    "\n",
    "def second_derivative_problem_6(x):\n",
    "    return -(abc_6[1]-x)*(abc_6[2]-x)-(abc_6[0]-x)*(abc_6[2]-x)-(abc_6[0]-x)*(abc_6[1]-x)\n",
    "\n",
    "def problem_7(x):\n",
    "    return -(x*(3*x**3+(-4*abc_7[2]-4*abc_7[1]-4*abc_7[0])*x**2+((6*abc_7[1]+6*abc_7[0])*abc_7[2]+6*abc_7[0]*abc_7[1])*x-12*abc_7[0]*abc_7[1]*abc_7[2]))/12\n",
    "\n",
    "def derivative_problem_7(x):\n",
    "    return (abc_7[0]-x)*(abc_7[1]-x)*(abc_7[2]-x)\n",
    "\n",
    "def second_derivative_problem_7(x):\n",
    "    return -(abc_7[1]-x)*(abc_7[2]-x)-(abc_7[0]-x)*(abc_7[2]-x)-(abc_7[0]-x)*(abc_7[1]-x)\n",
    "\n",
    "def problem_8(x):\n",
    "    return -(x*(3*x**3+(-4*abc_8[2]-4*abc_8[1]-4*abc_8[0])*x**2+((6*abc_8[1]+6*abc_8[0])*abc_8[2]+6*abc_8[0]*abc_8[1])*x-12*abc_8[0]*abc_8[1]*abc_8[2]))/12\n",
    "\n",
    "def derivative_problem_8(x):\n",
    "    return (abc_8[0]-x)*(abc_8[1]-x)*(abc_8[2]-x)\n",
    "\n",
    "def second_derivative_problem_8(x):\n",
    "    return -(abc_8[1]-x)*(abc_8[2]-x)-(abc_8[0]-x)*(abc_8[2]-x)-(abc_8[0]-x)*(abc_8[1]-x)\n",
    "\n",
    "def problem_9(x):\n",
    "    return -(x*(3*x**3+(-4*abc_9[2]-4*abc_9[1]-4*abc_9[0])*x**2+((6*abc_9[1]+6*abc_9[0])*abc_9[2]+6*abc_9[0]*abc_9[1])*x-12*abc_9[0]*abc_9[1]*abc_9[2]))/12\n",
    "\n",
    "def derivative_problem_9(x):\n",
    "    return (abc_9[0]-x)*(abc_9[1]-x)*(abc_9[2]-x)\n",
    "\n",
    "def second_derivative_problem_9(x):\n",
    "    return -(abc_9[1]-x)*(abc_9[2]-x)-(abc_9[0]-x)*(abc_9[2]-x)-(abc_9[0]-x)*(abc_9[1]-x)\n",
    "\n",
    "def problem_10(x):\n",
    "    return -(x*(3*x**3+(-4*abc_10[2]-4*abc_10[1]-4*abc_10[0])*x**2+((6*abc_10[1]+6*abc_10[0])*abc_10[2]+6*abc_10[0]*abc_10[1])*x-12*abc_10[0]*abc_10[1]*abc_10[2]))/12\n",
    "\n",
    "def derivative_problem_10(x):\n",
    "    return (abc_10[0]-x)*(abc_10[1]-x)*(abc_10[2]-x)\n",
    "\n",
    "def second_derivative_problem_10(x):\n",
    "    return -(abc_10[1]-x)*(abc_10[2]-x)-(abc_10[0]-x)*(abc_10[2]-x)-(abc_10[0]-x)*(abc_10[1]-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Run 5 tests<br></h4><br>\n",
    "<p><i>Place for your additional comments and argumentation<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performed 7 iterations.\n",
      "Initial x is :\t\t[[6]]\n",
      "Optimal x is :\t\t20.0\n",
      "Approximated x is :\t[[20.]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-328000.0\n",
      "Function value in approximated point:   [[-328000.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[3.25087512e-09]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]]\n",
      "============================================================================\n",
      "performed 7 iterations.\n",
      "Initial x is :\t\t[[60]]\n",
      "Optimal x is :\t\t50.0\n",
      "Approximated x is :\t[[50.]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-9062500.0\n",
      "Function value in approximated point:   [[-9062500.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[5.46492629e-08]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]]\n",
      "============================================================================\n",
      "performed 7 iterations.\n",
      "Initial x is :\t\t[[60]]\n",
      "Optimal x is :\t\t80.0\n",
      "Approximated x is :\t[[80.]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-53824000.0\n",
      "Function value in approximated point:   [[-53824000.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-0.]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]]\n",
      "============================================================================\n",
      "performed 7 iterations.\n",
      "Initial x is :\t\t[[60]]\n",
      "Optimal x is :\t\t100.0\n",
      "Approximated x is :\t[[100.]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-24166666.666666668\n",
      "Function value in approximated point:   [[-24166666.66666667]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-0.]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]]\n",
      "============================================================================\n",
      "performed 8 iterations.\n",
      "Initial x is :\t\t[[20]]\n",
      "Optimal x is :\t\t120.0\n",
      "Approximated x is :\t[[120.]]\n",
      "Is close verificaion: \t[[ True]]\n",
      "\n",
      "Function value in optimal point:\t-38016000.0\n",
      "Function value in approximated point:   [[-38016000.]]\n",
      "Is close verificaion:\t[[ True]]\n",
      "\n",
      "Gradient approximation in optimal point is:\n",
      "-0.0\n",
      "\n",
      "Gradient approximation in approximated point is:\n",
      "[[-0.]]\n",
      "\n",
      "Is close verificaion:\n",
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "x_start=np.array([[6]])\n",
    "x_hat=bfgs(x_start,problem_6, derivative_problem_6)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_6, abc_6), x_appr=x_hat, f=problem_6, grad=derivative_problem_6, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start=np.array([[60]])\n",
    "x_hat=bfgs(x_start, problem_7, derivative_problem_7)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_7, abc_7), x_appr=x_hat, f=problem_7, grad=derivative_problem_7, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start=np.array([[60]])\n",
    "x_hat=bfgs(x_start, problem_8, derivative_problem_8)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_8, abc_8), x_appr=x_hat, f=problem_8, grad=derivative_problem_8, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start=np.array([[60]])\n",
    "x_hat=bfgs(x_start, problem_9, derivative_problem_9)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_9, abc_9), x_appr=x_hat, f=problem_9, grad=derivative_problem_9, args={}, tolerance=1e-4)\n",
    "print(\"============================================================================\")\n",
    "x_start=np.array([[20]])\n",
    "x_hat=bfgs(x_start, problem_10, derivative_problem_10)\n",
    "final_printout(x_0=x_start, x_optimal=get_global_minimizer(problem_10, abc_10), x_appr=x_hat, f=problem_10, grad=derivative_problem_10, args={}, tolerance=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Here is some place for your analysis. How the behavour of algorithm changed after adjustments? What are specific details, differences you noticed with respect to other algorithms behaviour.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #D3D92B;\"><br>Template for teachers' tests<br></h3><br>\n",
    "<hr><h4 style=\"background-color: #ADB8FF;\"><br>Set up a template, how one can run your code<br></h4><br>\n",
    "Template should include sceletons for:<ul>\n",
    "    <li>custom function to optimise over </li> \n",
    "    <li>values initialisation to submit into otimising algorithm </li> \n",
    "    <li>optimiser function call</li> \n",
    "    <li>report print out call</li> </ul><br>\n",
    "Provide descriptions and comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
